{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory and Statistical Data Analysis for Iced company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to identify patterns that determine whether a game is successful or not for sale. This will allow us to detect promising projects and plan advertising campaigns for the following year (2017).\n",
    "\n",
    "To achieve the objective, the data received will be prepared, then analyzed in order to create a user profile for each of the relevant regions (North America, the European Union and Japan). Additionally, we will seek to answer the following hypotheses:\n",
    "1. Average user ratings for Xbox One and PC platforms are the same.\n",
    "2. Average user ratings for Action and Sports genres are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reading data and searching for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16715 entries, 0 to 16714\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   name             16713 non-null  object \n",
      " 1   platform         16715 non-null  object \n",
      " 2   year_of_release  16446 non-null  float64\n",
      " 3   genre            16713 non-null  object \n",
      " 4   na_sales         16715 non-null  float64\n",
      " 5   eu_sales         16715 non-null  float64\n",
      " 6   jp_sales         16715 non-null  float64\n",
      " 7   other_sales      16715 non-null  float64\n",
      " 8   critic_score     8137 non-null   float64\n",
      " 9   user_score       10014 non-null  object \n",
      " 10  rating           9949 non-null   object \n",
      "dtypes: float64(6), object(5)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "Duplicados:  0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../databases/games.csv')\n",
    "data.columns = data.columns.str.lower()\n",
    "print(data.info())\n",
    "\n",
    "# Búsqueda de duplicados:\n",
    "print('Duplicados: ',data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Datatype conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.  nan 8.3 8.5 6.6 8.4 8.6 7.7 6.3 7.4 8.2 9.  7.9 8.1 8.7 7.1 3.4 5.3\n",
      " 4.8 3.2 8.9 6.4 7.8 7.5 2.6 7.2 9.2 7.  7.3 4.3 7.6 5.7 5.  9.1 6.5 8.8\n",
      " 6.9 9.4 6.8 6.1 6.7 5.4 4.  4.9 4.5 9.3 6.2 4.2 6.  3.7 4.1 5.8 5.6 5.5\n",
      " 4.4 4.6 5.9 3.9 3.1 2.9 5.2 3.3 4.7 5.1 3.5 2.5 1.9 3.  2.7 2.2 2.  9.5\n",
      " 2.1 3.6 2.8 1.8 3.8 0.  1.6 9.6 2.4 1.7 1.1 0.3 1.5 0.7 1.2 2.3 0.5 1.3\n",
      " 0.2 0.6 1.4 0.9 1.  9.7]\n"
     ]
    }
   ],
   "source": [
    "## CAMBIAMOS EL TIPO DE DATO DE LA COLUMNA user_score ------------------\n",
    "#data['user_score'] = pd.to_numeric(data['user_score']) \n",
    "# En la coluna user_score tenemos datos no nulos, nulos y 'tbd'. Los nulos pueden provenir quizás de una mala captura de datos, o bien, aún no se han generado opiniones de los usuarios. Los 'tbd' sugieren tal vez actualizaciones en el score y este numero se este actualizando en la base de datos.\n",
    "\n",
    "# Como los valores tbd no aportan información y no hay forma de averiguar estos valores, se forzará el cambio de 'tbd' a valores numéricos y se transformarán a NaN:\n",
    "data['user_score'] = pd.to_numeric(data['user_score'], errors='coerce')\n",
    "print(data['user_score'].unique()) # There are no more 'tbd' values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Management of Null-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL PERCENTAGE OF NULL VALUES:\n",
      "name                0.011965\n",
      "platform            0.000000\n",
      "year_of_release     1.609333\n",
      "genre               0.011965\n",
      "na_sales            0.000000\n",
      "eu_sales            0.000000\n",
      "jp_sales            0.000000\n",
      "other_sales         0.000000\n",
      "critic_score       51.319174\n",
      "user_score         54.591684\n",
      "rating             40.478612\n",
      "dtype: float64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8. , nan, 8.3, 8.5, 6.6, 8.4, 8.6, 7.7, 6.3, 7.4, 8.2, 9. , 7.9,\n",
       "       8.1, 8.7, 7.1, 3.4, 5.3, 4.8, 3.2, 8.9, 6.4, 7.8, 7.5, 2.6, 7.2,\n",
       "       9.2, 7. , 7.3, 4.3, 7.6, 5.7, 5. , 9.1, 6.5, 8.8, 6.9, 9.4, 6.8,\n",
       "       6.1, 6.7, 5.4, 4. , 4.9, 4.5, 9.3, 6.2, 4.2, 6. , 3.7, 4.1, 5.8,\n",
       "       5.6, 5.5, 4.4, 4.6, 5.9, 3.9, 3.1, 2.9, 5.2, 3.3, 4.7, 5.1, 3.5,\n",
       "       2.5, 1.9, 3. , 2.7, 2.2, 2. , 9.5, 2.1, 3.6, 2.8, 1.8, 3.8, 0. ,\n",
       "       1.6, 9.6, 2.4, 1.7, 1.1, 0.3, 1.5, 0.7, 1.2, 2.3, 0.5, 1.3, 0.2,\n",
       "       0.6, 1.4, 0.9, 1. , 9.7])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL PERCENTAGE OF NULL VALUES:\n",
      "name                0.000000\n",
      "platform            0.000000\n",
      "year_of_release     0.831688\n",
      "genre               0.000000\n",
      "na_sales            0.000000\n",
      "eu_sales            0.000000\n",
      "jp_sales            0.000000\n",
      "other_sales         0.000000\n",
      "critic_score       51.313349\n",
      "user_score         54.586250\n",
      "rating             40.471489\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('INITIAL PERCENTAGE OF NULL VALUES:')\n",
    "print(100*data.isna().sum()/data.shape[0],'\\n')\n",
    "\n",
    "# COLUMN 'name':\n",
    "# Null values are eliminated on column \"name\":\n",
    "# Tenemos solo 2 valores ausentes:\n",
    "    #display(data[data['name'].isna()])\n",
    "# Eliminamos estas 2 filas del DF, dado que tiene mucha información NaN y no aporta mucho al DF:\n",
    "if len(data[data['name'].isna()]) != 0:\n",
    "    data = data.drop([659,14244], axis=0).reset_index(drop=True)\n",
    "else:\n",
    "    print(\"The column 'name' has no null values anymore\")\n",
    "#display(data.info())\n",
    "\n",
    "# COLUMN 'year_of_release':\n",
    "# Null values are filled on column 'year_of_release' with the information available on column 'name':\n",
    "    #  Vemos que en algunos casos el año de lanzamiento está implicito en el nombre del juego. Para estos casos, verificamos si el nombre tiene el año de lanzamiento, si lo  tiene, copiamos el año (transformado en float) a la columna 'year_of_release:\n",
    "    #   Definimos una función para extraer el año de 'name' usando expresiones regulares:\n",
    "def extract_year(dataframe):\n",
    "    match = re.search(r'\\b(\\d{4})\\b', dataframe['name'])\n",
    "    return float(match.group(1)) if match else dataframe['year_of_release']\n",
    "\n",
    "years = data.apply(extract_year, axis=1) # Se extrae el año del nombre\n",
    "data['year_of_release'] = data['year_of_release'].fillna(years) # Llenamos los valores ausentes hallados\n",
    "#print(data.info())\n",
    "\n",
    "# Null values are filled on column 'year_of_release' for multiplatform games:\n",
    "    #df_prueba = data[data['year_of_release'].isna()]\n",
    "    #display(df_prueba) # Vemos que aún hay valores ausentes, como por ejemplo: LEGO Batman: The Videogame\n",
    "    # Corroboremos que no hay otras instancias del mismo juego que sí tengan año de lanzamiento. En caso de haber, debemos asignar ese año a los valores ausentes de 'year_of_release' de ese juego:\n",
    "    #display(data[data['name']=='LEGO Batman: The Videogame'])\n",
    "    # Con lo anterior corroboramos que puede haber juegos repetidos para multiples plataformas, pero que en algunas de ellas no está definido el año de lanzamiento. Usaremos entonces, las plataformas que sí tienen año de lanzaminto definido para asignarle el año a aquellos juegos que no lo tengan.\n",
    "lista_juegos = data.groupby('name')['year_of_release'].median().round() #Usamos la mediana para obtener el valor común\n",
    "data['year_of_release'] = data.set_index('name')['year_of_release'].fillna(lista_juegos).reset_index(drop=True)\n",
    "#display(data.info())\n",
    "\n",
    "print('\\nFINAL PERCENTAGE OF NULL VALUES:')\n",
    "print(100*data.isna().sum()/data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After this procedure, there are still 139 games with a null-value in ***year_of_release***, however, it is no longer possible to find out the missing values with the information available in the DF\n",
    "- For null values in the ***critic_score***, ***user_score*** and ***rating*** columns, there is not enough information in the DF to remove or replace these null values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Total sales computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de las ventas totales:\n",
    "data['total_sales'] = data['na_sales'] + data['eu_sales'] + data['jp_sales'] + data['other_sales']\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis\n",
    "#### How many games were released in different years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_by_year = data.groupby('year_of_release')['name'].count()\n",
    "#display(games_by_year)\n",
    "plt.figure(1, figsize=(15,5))\n",
    "games_by_year.plot(kind='bar', xlabel='Year of Release', ylabel='Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the difference in games released is quite different in each year, with 2008 and 2009 being the years where the most video games were launched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How sales vary from one platform to another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_platform_sales = data.groupby(['year_of_release','platform'])['total_sales'].sum()\n",
    "display(top_platform_sales['2016'])\n",
    "display(type(top_platform_sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['platform']=='PSV') & (data['year_of_release']=='2016')]['total_sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1,2,3,np.nan]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
